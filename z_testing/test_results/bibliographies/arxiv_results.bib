@article{Yin_2025_1,
  title = {ConsistEdit: Highly Consistent and Precise Training-free Visual Editing},
  author = {Zixin Yin and Ling-Hao Chen and Lionel Ni and Xili Dai},
  year = {2025},
  url = {https://arxiv.org/abs/2510.17803v1},
  abstract = {Recent advances in training-free attention control methods have enabled flexible and efficient text-guided editing capabilities for existing generation models. However, current approaches struggle to simultaneously deliver strong editing strength while preserving consistency with the source. This limitation becomes particularly critical in multi-round and video editing, where visual errors can accumulate over time. Moreover, most existing methods enforce global consistency, which limits their...},
  note = {Source: arXiv},
}

@article{Cheng_2025_2,
  title = {Glyph: Scaling Context Windows via Visual-Text Compression},
  author = {Jiale Cheng and Yusen Liu and Xinyu Zhang and Yulin Fei and Wenyi Hong and Ruiliang Lyu and Weihan Wang and Zhe Su and Xiaotao Gu and Xiao Liu and Yushi Bai and Jie Tang and Hongning Wang and Minlie Huang},
  year = {2025},
  url = {https://arxiv.org/abs/2510.17800v1},
  abstract = {Large language models (LLMs) increasingly rely on long-context modeling for tasks such as document understanding, code analysis, and multi-step reasoning. However, scaling context windows to the million-token level brings prohibitive computational and memory costs, limiting the practicality of long-context LLMs. In this work, we take a different perspective-visual context scaling-to tackle this challenge. Instead of extending token-based sequences, we propose Glyph, a framework that renders l...},
  note = {Source: arXiv},
}

@article{Prabhakar_2025_3,
  title = {Enterprise Deep Research: Steerable Multi-Agent Deep Research for   Enterprise Analytics},
  author = {Akshara Prabhakar and Roshan Ram and Zixiang Chen and Silvio Savarese and Frank Wang and Caiming Xiong and Huan Wang and Weiran Yao},
  year = {2025},
  url = {https://arxiv.org/abs/2510.17797v1},
  abstract = {As information grows exponentially, enterprises face increasing pressure to transform unstructured data into coherent, actionable insights. While autonomous agents show promise, they often struggle with domain-specific nuances, intent alignment, and enterprise integration. We present Enterprise Deep Research (EDR), a multi-agent system that integrates (1) a Master Planning Agent for adaptive query decomposition, (2) four specialized search agents (General, Academic, GitHub, LinkedIn), (3) an ...},
  note = {Source: arXiv},
}

