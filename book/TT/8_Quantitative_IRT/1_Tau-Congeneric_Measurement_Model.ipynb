{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.1 Tau Congeneric models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usage\n",
    "\n",
    "This notebook illustrates the **tau-congeneric measurement model** using `Data_EmotionalClarity.dat`. Load the dataset, explore descriptive statistics, and fit the model via `lavaan` with `rpy2`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HFAtMBiOL8ZN"
   },
   "source": [
    "## **The dataset**\n",
    "\n",
    "For this exercise we use a dataset from Lischetzke (2003). The construct we want to measure is **emotional clarity** by means of reaction times (RT) on a mood intensity scale. It is assumed that the faster people assess their mood, the greater the emotional clarity.\n",
    "\n",
    "## **Load and inspect the full data set**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maku1542\\AppData\\Local\\miniconda3\\envs\\psy126\\Lib\\site-packages\\rpy2\\robjects\\packages.py:367: UserWarning: The symbol 'quartz' is not in this R namespace/package.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "rpy2.robjects.packages.Package as a <module 'stats'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Rpy2 imports\n",
    "from rpy2 import robjects as ro\n",
    "from rpy2.robjects import pandas2ri, numpy2ri\n",
    "from rpy2.robjects.packages import importr\n",
    "\n",
    "# Automatic conversion of arrays and dataframes\n",
    "pandas2ri.activate()\n",
    "numpy2ri.activate()\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "ro.r('set.seed(123)')\n",
    "\n",
    "# Ipython extenrsion for magix plotting\n",
    "%load_ext rpy2.ipython\n",
    "\n",
    "# R imports\n",
    "importr('base')\n",
    "importr('lavaan')\n",
    "importr('psych')\n",
    "importr('stats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1741813821624,
     "user": {
      "displayName": "Tim Dreßler",
      "userId": "10678244503421566183"
     },
     "user_tz": -60
    },
    "id": "wZWFF8nMMFFQ",
    "outputId": "7ba8c27e-c97a-4746-b793-481e91ab21cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sex    item_1    item_2    item_3    item_4    item_5    item_6\n",
      "0    1  1.463255  1.739589  1.384292  1.568408  1.457452  1.628260\n",
      "1    1  1.689358  1.789256  1.771557  1.696533  1.395997  1.842294\n",
      "2    0  1.300736  1.492455  1.347294  1.178347  1.784903  1.221125\n",
      "3    0  1.588419  1.459545  1.300736  1.278152  1.145496  1.446213\n",
      "4    0  1.182953  0.914289  0.997686  1.357895  0.875052  1.232852\n"
     ]
    }
   ],
   "source": [
    "file_name = \"data/Data_EmotionalClarity.dat\"\n",
    "dat = pd.read_csv(file_name, sep=\"\\t\")\n",
    "print(dat.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_RpFxasHMFZ6"
   },
   "source": [
    "### **Extract items 1 to 6 for the analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1741813866286,
     "user": {
      "displayName": "Tim Dreßler",
      "userId": "10678244503421566183"
     },
     "user_tz": -60
    },
    "id": "7yW-as2CMLYc",
    "outputId": "660029ab-fb79-48b5-c000-89297bab8534"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     item_1    item_2    item_3    item_4    item_5    item_6\n",
      "0  1.463255  1.739589  1.384292  1.568408  1.457452  1.628260\n",
      "1  1.689358  1.789256  1.771557  1.696533  1.395997  1.842294\n",
      "2  1.300736  1.492455  1.347294  1.178347  1.784903  1.221125\n",
      "3  1.588419  1.459545  1.300736  1.278152  1.145496  1.446213\n",
      "4  1.182953  0.914289  0.997686  1.357895  0.875052  1.232852\n"
     ]
    }
   ],
   "source": [
    "dat2 = dat.iloc[:, 1:7]\n",
    "print(dat2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qUgh-zyFMRpC"
   },
   "source": [
    "# Tau-Congeneric Measurement Model\n",
    "We will now start testing the measurement models that were covered in lecture section of this course two weeks ago.\n",
    "\n",
    "The **Tau Congeneric** measurement model is the least restrictive one out of the measurement models that we will use today. It assumes that:\n",
    "\n",
    "* items differ in their difficulty\n",
    "* items differ in their discrimination power\n",
    "* items vary in their reliability  \n",
    "\n",
    "We therefore obtain estimates for the loadings (`Latent Variables` section), the intercepts (`Intercepts` section), and the errors (`Variances` section).\n",
    "\n",
    "## Fit the model\n",
    "We are now going to define the model using `lavaan` syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 143,
     "status": "ok",
     "timestamp": 1741814750617,
     "user": {
      "displayName": "Tim Dreßler",
      "userId": "10678244503421566183"
     },
     "user_tz": -60
    },
    "id": "YJN8o0gcNsEi",
    "outputId": "02c0e589-876d-40be-f374-459dc69ce3cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lavaan 0.6-19 ended normally after 38 iterations\n",
      "\n",
      "  Estimator                                         ML\n",
      "  Optimization method                           NLMINB\n",
      "  Number of model parameters                        18\n",
      "\n",
      "  Number of observations                           238\n",
      "\n",
      "Model Test User Model:\n",
      "                                                      \n",
      "  Test statistic                                 9.568\n",
      "  Degrees of freedom                                 9\n",
      "  P-value (Chi-square)                           0.387\n",
      "\n",
      "Model Test Baseline Model:\n",
      "\n",
      "  Test statistic                               435.847\n",
      "  Degrees of freedom                                15\n",
      "  P-value                                        0.000\n",
      "\n",
      "User Model versus Baseline Model:\n",
      "\n",
      "  Comparative Fit Index (CFI)                    0.999\n",
      "  Tucker-Lewis Index (TLI)                       0.998\n",
      "\n",
      "Loglikelihood and Information Criteria:\n",
      "\n",
      "  Loglikelihood user model (H0)               -432.180\n",
      "  Loglikelihood unrestricted model (H1)       -427.396\n",
      "                                                      \n",
      "  Akaike (AIC)                                 900.360\n",
      "  Bayesian (BIC)                               962.861\n",
      "  Sample-size adjusted Bayesian (SABIC)        905.806\n",
      "\n",
      "Root Mean Square Error of Approximation:\n",
      "\n",
      "  RMSEA                                          0.016\n",
      "  90 Percent confidence interval - lower         0.000\n",
      "  90 Percent confidence interval - upper         0.076\n",
      "  P-value H_0: RMSEA <= 0.050                    0.763\n",
      "  P-value H_0: RMSEA >= 0.080                    0.036\n",
      "\n",
      "Standardized Root Mean Square Residual:\n",
      "\n",
      "  SRMR                                           0.021\n",
      "\n",
      "Parameter Estimates:\n",
      "\n",
      "  Standard errors                             Standard\n",
      "  Information                                 Expected\n",
      "  Information saturated (h1) model          Structured\n",
      "\n",
      "Latent Variables:\n",
      "                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n",
      "  eta =~                                                                \n",
      "    item_1            1.000                               0.229    0.638\n",
      "    item_2            1.098    0.131    8.404    0.000    0.251    0.682\n",
      "    item_3            1.194    0.140    8.535    0.000    0.273    0.697\n",
      "    item_4            1.294    0.147    8.790    0.000    0.296    0.728\n",
      "    item_5            1.032    0.131    7.886    0.000    0.236    0.628\n",
      "    item_6            1.049    0.133    7.886    0.000    0.240    0.628\n",
      "\n",
      "Intercepts:\n",
      "                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n",
      "   .item_1            1.504    0.023   64.757    0.000    1.504    4.198\n",
      "   .item_2            1.423    0.024   59.647    0.000    1.423    3.866\n",
      "   .item_3            1.392    0.025   54.862    0.000    1.392    3.556\n",
      "   .item_4            1.305    0.026   49.486    0.000    1.305    3.208\n",
      "   .item_5            1.346    0.024   55.221    0.000    1.346    3.579\n",
      "   .item_6            1.306    0.025   52.662    0.000    1.306    3.414\n",
      "\n",
      "Variances:\n",
      "                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n",
      "   .item_1            0.076    0.008    9.363    0.000    0.076    0.593\n",
      "   .item_2            0.072    0.008    8.941    0.000    0.072    0.534\n",
      "   .item_3            0.079    0.009    8.770    0.000    0.079    0.514\n",
      "   .item_4            0.078    0.009    8.362    0.000    0.078    0.471\n",
      "   .item_5            0.086    0.009    9.449    0.000    0.086    0.606\n",
      "   .item_6            0.089    0.009    9.449    0.000    0.089    0.606\n",
      "    eta               0.052    0.010    5.051    0.000    1.000    1.000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Put data into R\n",
    "ro.globalenv['dat2'] = dat2\n",
    "# Specify the model\n",
    "ro.r(\"mtc <- 'eta =~ item_1 + item_2 + item_3 + item_4 + item_5 + item_6'\")\n",
    "# Fit the model\n",
    "ro.r('fitmtc <- sem(mtc, data=dat2, meanstructure=TRUE)')\n",
    "# Print the output of the model for interpretation\n",
    "summary_fitmtc = ro.r(\"summary(fitmtc, fit.measures=TRUE, standardized=TRUE)\")\n",
    "print(summary_fitmtc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively you can have you parameters organized tidly in a dataframe, similar to the `semopy` outputs from [last semester](https://mibur1.github.io/psy111/book/statistics/7_CFA_SEM/0_Introduction.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lhs</th>\n",
       "      <th>op</th>\n",
       "      <th>rhs</th>\n",
       "      <th>est</th>\n",
       "      <th>se</th>\n",
       "      <th>z</th>\n",
       "      <th>pvalue</th>\n",
       "      <th>ci.lower</th>\n",
       "      <th>ci.upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eta</td>\n",
       "      <td>=~</td>\n",
       "      <td>item_1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eta</td>\n",
       "      <td>=~</td>\n",
       "      <td>item_2</td>\n",
       "      <td>1.098183</td>\n",
       "      <td>0.130681</td>\n",
       "      <td>8.403543</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.842053</td>\n",
       "      <td>1.354313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eta</td>\n",
       "      <td>=~</td>\n",
       "      <td>item_3</td>\n",
       "      <td>1.193622</td>\n",
       "      <td>0.139846</td>\n",
       "      <td>8.535263</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.919529</td>\n",
       "      <td>1.467715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eta</td>\n",
       "      <td>=~</td>\n",
       "      <td>item_4</td>\n",
       "      <td>1.294106</td>\n",
       "      <td>0.147228</td>\n",
       "      <td>8.789826</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.005545</td>\n",
       "      <td>1.582667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>eta</td>\n",
       "      <td>=~</td>\n",
       "      <td>item_5</td>\n",
       "      <td>1.032055</td>\n",
       "      <td>0.130870</td>\n",
       "      <td>7.886123</td>\n",
       "      <td>3.108624e-15</td>\n",
       "      <td>0.775555</td>\n",
       "      <td>1.288555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>eta</td>\n",
       "      <td>=~</td>\n",
       "      <td>item_6</td>\n",
       "      <td>1.049491</td>\n",
       "      <td>0.133084</td>\n",
       "      <td>7.885902</td>\n",
       "      <td>3.108624e-15</td>\n",
       "      <td>0.788650</td>\n",
       "      <td>1.310332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>item_1</td>\n",
       "      <td>~~</td>\n",
       "      <td>item_1</td>\n",
       "      <td>0.076077</td>\n",
       "      <td>0.008125</td>\n",
       "      <td>9.362691</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.060151</td>\n",
       "      <td>0.092002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>item_2</td>\n",
       "      <td>~~</td>\n",
       "      <td>item_2</td>\n",
       "      <td>0.072360</td>\n",
       "      <td>0.008093</td>\n",
       "      <td>8.941056</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.056498</td>\n",
       "      <td>0.088222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>item_3</td>\n",
       "      <td>~~</td>\n",
       "      <td>item_3</td>\n",
       "      <td>0.078730</td>\n",
       "      <td>0.008978</td>\n",
       "      <td>8.769699</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.061135</td>\n",
       "      <td>0.096326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>item_4</td>\n",
       "      <td>~~</td>\n",
       "      <td>item_4</td>\n",
       "      <td>0.077839</td>\n",
       "      <td>0.009309</td>\n",
       "      <td>8.361802</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.059594</td>\n",
       "      <td>0.096085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>item_5</td>\n",
       "      <td>~~</td>\n",
       "      <td>item_5</td>\n",
       "      <td>0.085767</td>\n",
       "      <td>0.009077</td>\n",
       "      <td>9.449296</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.067977</td>\n",
       "      <td>0.103556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>item_6</td>\n",
       "      <td>~~</td>\n",
       "      <td>item_6</td>\n",
       "      <td>0.088700</td>\n",
       "      <td>0.009387</td>\n",
       "      <td>9.449471</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.070302</td>\n",
       "      <td>0.107097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>eta</td>\n",
       "      <td>~~</td>\n",
       "      <td>eta</td>\n",
       "      <td>0.052306</td>\n",
       "      <td>0.010357</td>\n",
       "      <td>5.050545</td>\n",
       "      <td>4.405515e-07</td>\n",
       "      <td>0.032008</td>\n",
       "      <td>0.072604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>item_1</td>\n",
       "      <td>~1</td>\n",
       "      <td></td>\n",
       "      <td>1.504005</td>\n",
       "      <td>0.023225</td>\n",
       "      <td>64.756711</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.458484</td>\n",
       "      <td>1.549526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>item_2</td>\n",
       "      <td>~1</td>\n",
       "      <td></td>\n",
       "      <td>1.422903</td>\n",
       "      <td>0.023855</td>\n",
       "      <td>59.647002</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.376148</td>\n",
       "      <td>1.469659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>item_3</td>\n",
       "      <td>~1</td>\n",
       "      <td></td>\n",
       "      <td>1.392156</td>\n",
       "      <td>0.025376</td>\n",
       "      <td>54.862182</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.342421</td>\n",
       "      <td>1.441892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>item_4</td>\n",
       "      <td>~1</td>\n",
       "      <td></td>\n",
       "      <td>1.304696</td>\n",
       "      <td>0.026365</td>\n",
       "      <td>49.485916</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.253021</td>\n",
       "      <td>1.356370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>item_5</td>\n",
       "      <td>~1</td>\n",
       "      <td></td>\n",
       "      <td>1.346359</td>\n",
       "      <td>0.024381</td>\n",
       "      <td>55.220698</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.298572</td>\n",
       "      <td>1.394145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>item_6</td>\n",
       "      <td>~1</td>\n",
       "      <td></td>\n",
       "      <td>1.305712</td>\n",
       "      <td>0.024794</td>\n",
       "      <td>52.661972</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.257117</td>\n",
       "      <td>1.354308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>eta</td>\n",
       "      <td>~1</td>\n",
       "      <td></td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       lhs  op     rhs       est        se          z        pvalue  ci.lower  \\\n",
       "1      eta  =~  item_1  1.000000  0.000000        NaN           NaN  1.000000   \n",
       "2      eta  =~  item_2  1.098183  0.130681   8.403543  0.000000e+00  0.842053   \n",
       "3      eta  =~  item_3  1.193622  0.139846   8.535263  0.000000e+00  0.919529   \n",
       "4      eta  =~  item_4  1.294106  0.147228   8.789826  0.000000e+00  1.005545   \n",
       "5      eta  =~  item_5  1.032055  0.130870   7.886123  3.108624e-15  0.775555   \n",
       "6      eta  =~  item_6  1.049491  0.133084   7.885902  3.108624e-15  0.788650   \n",
       "7   item_1  ~~  item_1  0.076077  0.008125   9.362691  0.000000e+00  0.060151   \n",
       "8   item_2  ~~  item_2  0.072360  0.008093   8.941056  0.000000e+00  0.056498   \n",
       "9   item_3  ~~  item_3  0.078730  0.008978   8.769699  0.000000e+00  0.061135   \n",
       "10  item_4  ~~  item_4  0.077839  0.009309   8.361802  0.000000e+00  0.059594   \n",
       "11  item_5  ~~  item_5  0.085767  0.009077   9.449296  0.000000e+00  0.067977   \n",
       "12  item_6  ~~  item_6  0.088700  0.009387   9.449471  0.000000e+00  0.070302   \n",
       "13     eta  ~~     eta  0.052306  0.010357   5.050545  4.405515e-07  0.032008   \n",
       "14  item_1  ~1          1.504005  0.023225  64.756711  0.000000e+00  1.458484   \n",
       "15  item_2  ~1          1.422903  0.023855  59.647002  0.000000e+00  1.376148   \n",
       "16  item_3  ~1          1.392156  0.025376  54.862182  0.000000e+00  1.342421   \n",
       "17  item_4  ~1          1.304696  0.026365  49.485916  0.000000e+00  1.253021   \n",
       "18  item_5  ~1          1.346359  0.024381  55.220698  0.000000e+00  1.298572   \n",
       "19  item_6  ~1          1.305712  0.024794  52.661972  0.000000e+00  1.257117   \n",
       "20     eta  ~1          0.000000  0.000000        NaN           NaN  0.000000   \n",
       "\n",
       "    ci.upper  \n",
       "1   1.000000  \n",
       "2   1.354313  \n",
       "3   1.467715  \n",
       "4   1.582667  \n",
       "5   1.288555  \n",
       "6   1.310332  \n",
       "7   0.092002  \n",
       "8   0.088222  \n",
       "9   0.096326  \n",
       "10  0.096085  \n",
       "11  0.103556  \n",
       "12  0.107097  \n",
       "13  0.072604  \n",
       "14  1.549526  \n",
       "15  1.469659  \n",
       "16  1.441892  \n",
       "17  1.356370  \n",
       "18  1.394145  \n",
       "19  1.354308  \n",
       "20  0.000000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe = ro.r('parameterEstimates(fitmtc)')        # R → pandas\n",
    "pe = pandas2ri.rpy2py(pe)\n",
    "pe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NUUvryQ0QF8j"
   },
   "source": [
    "### **Model fit**\n",
    "\n",
    "Before we look at the model parameters, let's first review the model fit indices.  \n",
    "The insignificant p-value for the $\\chi^2$ test indicates that our model implied correlation matrix doesn't deviate significantly from the data implied correlation matrix, suggesting a good fit. Furthermore, the CFI and TLI are > .95, also indicating a good fit. AIC and BIC can't be interpreted individually but will be later used for comparing models (see below). Lastly, the RMSEA and SRMR are also < .08, also suggesting a good fit. In summary, all indices suggest that the models fits our data well.  \n",
    "As a reminder - the usual limit value / criteria for the various fit indices:\n",
    "\n",
    "- `Chi-square` / `Chi-square p-value`: The $\\chi^2$-Test tests the null hypothesis that the model implied covariance matrix is equal to the empirical (actual) covariance matrix. Therefore, a **low** test statistic (and a non-significant p-value) indicate good fit.\n",
    "- `CFI`: The **CFI** compares the fit of your user-specified model to the baseline model, with values closer to 1 indicating that the user model has a much better fit. > .95 desirable\n",
    "- `AIC` & `BIC`: measures of the relative quality of the statistical model for a given set of data (**BIC** includes a penalty for the number of parameters in the model). Lower **AIC** & **BIC** values indicate a better model. This statistic can be only used for comparison but not as an absolute criterion.\n",
    "- `RMSEA`: The **RMSEA** can be seen as a statistic derived from the $\\chi^2$ test, adjusted for model complexity and less influenced by sample size. An RMSEA value of <0.08 indicates an adequate fit.\n",
    "\n",
    "### **Latent variables section**\n",
    "\n",
    "Increasing loadings can be interpreted as the respective item having a higher discrimination power.\n",
    "For example, `item_1` has a loading of 1.098 while `item_4` has a loading of 1.294, meaning that the same increase in the latent variable (i.e. the trait we\n",
    "measure) results in a larger difference in `item_4` compared to `item_1`. Graphically this is represented by `item_4` having a steeper slope. You might notice that the loadings are quite similar across items; keep this in mind for later.\n",
    "\n",
    "### **Intercepts section**\n",
    "\n",
    "The intercepts can be used to interpret the difficulty of the item. Here, bigger values indicate that an item is **more** difficult. However, watch out: The interpretation can differ in other cases. Here, larger intercepts relate to larger reaction times, meaning, according to the theory, the mood which is assessed with this item is 'less emotionally clear'. On the other hand, if we would like to assess intelligence by the percentage of correct answers in a test, a larger intercept would mean that even individuals with 0 (or average, if centered) intelligence would end up with a large percentage of correct answers, meaning our item is actually to **easy**.\n",
    "(Technically, you can always say that an item associated with a larger intercept is more difficult. However, the explicit interpretation can differ).\n",
    "\n",
    "### **Variances section**\n",
    "\n",
    "The Variances refer to the reliability of the items. Speaking in a 'CFA-Language', they represent the residuals (errors) associated with the items. In the last row, the variance of the latent variable is shown.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1shSM8oE3V3nElvkpfKPtfJNamsVKnTSR",
     "timestamp": 1741293629262
    },
    {
     "file_id": "1oY59GO8mlzEJZlf-csY2pKRUXDCCIMFo",
     "timestamp": 1741164113567
    },
    {
     "file_id": "1_Hdy9GX2W03RQoKnijnEid9-KJzzTmJi",
     "timestamp": 1740862927421
    }
   ]
  },
  "kernelspec": {
   "display_name": "psy126",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
