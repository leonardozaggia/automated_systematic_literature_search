{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "746430cc",
   "metadata": {},
   "source": [
    "# 6.2 Tau-Equivalent Models\n",
    "## Essentially Tau-Equivalent Model\n",
    "\n",
    "The **Essentially tau-equivalent** measurement model is also quite flexible but it has one more restriction compared to the **Tau Congeneric** measurement model. It assumes that\n",
    "\n",
    "* items differ in their difficulty\n",
    "* items **are equivalent in their discrimination power**\n",
    "* items are differently reliable  \n",
    "\n",
    "We therefore get an estimate for the intercepts (`Intecepts` section) and for the errors (`Variances` section). Note that we also get a `Latent Variables` section again, however, you will have to fix all the loadings to 1.\n",
    "\n",
    "## Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b56a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from semopy import Model, calc_stats\n",
    "\n",
    "file_name = \"/Users/amnesia/Desktop/repos/psy126/book/TT/8_Quantitative_IRT/data/Data_EmotionalClarity.dat\"\n",
    "dat = pd.read_csv(file_name, sep=\"\\t\")\n",
    "dat2 = dat.iloc[:, 1:7]\n",
    "\n",
    "model_desc = '''\n",
    "eta =~ item_1 + item_2 + item_3 + item_4 + item_5 + item_6\n",
    "'''\n",
    "mtc_model = Model(model_desc)\n",
    "model.fit(dat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe0dd0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter Estimates (standardized):\n",
      "      lval  op    rval  Estimate  Est. Std  Std. Err   z-value p-value\n",
      "0   item_1   ~     eta  1.000000  0.681985         -         -       -\n",
      "1   item_2   ~     eta  1.000000  0.689287         -         -       -\n",
      "2   item_3   ~     eta  1.000000  0.664009         -         -       -\n",
      "3   item_4   ~     eta  1.000000  0.655781         -         -       -\n",
      "4   item_5   ~     eta  1.000000  0.656691         -         -       -\n",
      "5   item_6   ~     eta  1.000000  0.650229         -         -       -\n",
      "6      eta  ~~     eta  0.064242  1.000000  0.007135  9.003744     0.0\n",
      "7   item_1  ~~  item_1  0.073882  0.534896  0.007983  9.254501     0.0\n",
      "8   item_2  ~~  item_2  0.070971  0.524884  0.007726  9.185963     0.0\n",
      "9   item_3  ~~  item_3  0.081462  0.559092  0.008657  9.409939     0.0\n",
      "10  item_4  ~~  item_4  0.085141  0.569951  0.008986  9.475357     0.0\n",
      "11  item_5  ~~  item_5  0.084728  0.568757  0.008949  9.468285     0.0\n",
      "12  item_6  ~~  item_6  0.087703  0.577202  0.009215  9.517646     0.0\n",
      "\n",
      "Fit Statistics:\n",
      "       DoF  DoF Baseline       chi2  chi2 p-value  chi2 Baseline       CFI  \\\n",
      "Value   14            15  16.948756      0.258919     435.847342  0.992993   \n",
      "\n",
      "            GFI      AGFI       NFI       TLI     RMSEA        AIC        BIC  \\\n",
      "Value  0.961113  0.958335  0.961113  0.992493  0.029811  13.857573  38.163468   \n",
      "\n",
      "         LogLik  \n",
      "Value  0.071213  \n"
     ]
    }
   ],
   "source": [
    "# Metric Model using semopy\n",
    "from semopy import Model, calc_stats\n",
    "\n",
    "\n",
    "model_desc = '''\n",
    "eta =~ item_1 + item_2 + item_3 + item_4 + item_5 + item_6\n",
    "'''\n",
    "mtc_model = Model(model_desc)\n",
    "model.fit(dat2)\n",
    "\n",
    "model_mete = '''\n",
    "eta =~ 1*item_1 + 1*item_2 + 1*item_3 + 1*item_4 + 1*item_5 + 1*item_6\n",
    "'''\n",
    "met_model = Model(model_mete)\n",
    "met_model.fit(dat2)\n",
    "print(\"Parameter Estimates (standardized):\")\n",
    "print(met_model.inspect(std_est=True))\n",
    "\n",
    "print(\"\\nFit Statistics:\")\n",
    "stats_mete = calc_stats(met_model)\n",
    "print(stats_mete)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91eded9",
   "metadata": {},
   "source": [
    "You can see that the output looks very similar to the one from the **Tau Congeneric** measurement model. The interpretation of the intercepts (`Intecepts` section) and for the errors (`Variances` section) is the same as before. The only difference is that the loadings (`Latent Variables` section) are all fixed to one, meaning that we assume that all items have the same discriminatory power. Graphically speaking, this means that the slopes of the items are equivalent. The interpretation of the fit indices is analogous to the **Tau Congeneric** measurement model (see above).\n",
    "\n",
    "### Compare model fit\n",
    "\n",
    "Next, lets compare the models we just fitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c420dec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-square difference: Value    7.380404\n",
      "Name: chi2, dtype: float64, DF difference: 5, p-value: [0.19385117]\n",
      "\n",
      "AIC tau-equivalent: Value    13.857573\n",
      "Name: AIC, dtype: float64, AIC tau-congeneric: Value    23.919594\n",
      "Name: AIC, dtype: float64\n",
      "\n",
      "BIC tau-equivalent: Value    38.163468\n",
      "Name: BIC, dtype: float64, BIC tau-congeneric: Value    65.586842\n",
      "Name: BIC, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/83/txm_0k613c57n_1tncgxh2qc0000gn/T/ipykernel_65548/1381848602.py:22: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
      "  df_mtc = int(stats_mtc['DoF'])\n",
      "/var/folders/83/txm_0k613c57n_1tncgxh2qc0000gn/T/ipykernel_65548/1381848602.py:24: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
      "  df_mete = int(stats_mete['DoF'])\n"
     ]
    }
   ],
   "source": [
    "from semopy import Model, calc_stats\n",
    "from scipy.stats import chi2\n",
    "\n",
    "# Fit the less restricted (tau-congeneric) model\n",
    "model_desc = '''\n",
    "eta =~ item_1 + item_2 + item_3 + item_4 + item_5 + item_6\n",
    "'''\n",
    "mtc_model = Model(model_desc)\n",
    "mtc_model.fit(dat2)\n",
    "stats_mtc = calc_stats(mtc_model)\n",
    "\n",
    "# Fit the more restricted (essentially tau-equivalent) model\n",
    "model_mete = '''\n",
    "eta =~ 1*item_1 + 1*item_2 + 1*item_3 + 1*item_4 + 1*item_5 + 1*item_6\n",
    "'''\n",
    "met_model = Model(model_mete)\n",
    "met_model.fit(dat2)\n",
    "stats_mete = calc_stats(met_model)\n",
    "\n",
    "# Extract chi-square and degrees of freedom\n",
    "chisq_mtc = stats_mtc['chi2']\n",
    "df_mtc = int(stats_mtc['DoF'])\n",
    "chisq_mete = stats_mete['chi2']\n",
    "df_mete = int(stats_mete['DoF'])\n",
    "\n",
    "# Compute differences\n",
    "chi_diff = chisq_mete - chisq_mtc\n",
    "df_diff = df_mete - df_mtc\n",
    "p_value = chi2.sf(chi_diff, df_diff)\n",
    "\n",
    "print(f'Chi-square difference: {chi_diff}, DF difference: {df_diff}, p-value: {p_value}')\n",
    "print(f'\\nAIC tau-equivalent: {stats_mete['AIC']}, AIC tau-congeneric: {stats_mtc['AIC']}')\n",
    "print(f'\\nBIC tau-equivalent: {stats_mete['BIC']}, BIC tau-congeneric: {stats_mtc['BIC']}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54ac3d6a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Value'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/psy126/lib/python3.13/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'Value'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstats\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m chi2\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Assuming stats_mete and stats_tc (for tau-congeneric) exist\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m chisq_mete = \u001b[43mstats_mete\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mChi-Squared\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mValue\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m      6\u001b[39m df_mete = \u001b[38;5;28mint\u001b[39m(stats_mete.loc[\u001b[33m'\u001b[39m\u001b[33mDoF\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mValue\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m      7\u001b[39m chisq_tc = stats_tc.loc[\u001b[33m'\u001b[39m\u001b[33mChi-Squared\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mValue\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/psy126/lib/python3.13/site-packages/pandas/core/indexing.py:1183\u001b[39m, in \u001b[36m_LocationIndexer.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1181\u001b[39m     key = \u001b[38;5;28mtuple\u001b[39m(com.apply_if_callable(x, \u001b[38;5;28mself\u001b[39m.obj) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m key)\n\u001b[32m   1182\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._is_scalar_access(key):\n\u001b[32m-> \u001b[39m\u001b[32m1183\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtakeable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_takeable\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1184\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_tuple(key)\n\u001b[32m   1185\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1186\u001b[39m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/psy126/lib/python3.13/site-packages/pandas/core/frame.py:4219\u001b[39m, in \u001b[36mDataFrame._get_value\u001b[39m\u001b[34m(self, index, col, takeable)\u001b[39m\n\u001b[32m   4216\u001b[39m     series = \u001b[38;5;28mself\u001b[39m._ixs(col, axis=\u001b[32m1\u001b[39m)\n\u001b[32m   4217\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m series._values[index]\n\u001b[32m-> \u001b[39m\u001b[32m4219\u001b[39m series = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_item_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4220\u001b[39m engine = \u001b[38;5;28mself\u001b[39m.index._engine\n\u001b[32m   4222\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.index, MultiIndex):\n\u001b[32m   4223\u001b[39m     \u001b[38;5;66;03m# CategoricalIndex: Trying to use the engine fastpath may give incorrect\u001b[39;00m\n\u001b[32m   4224\u001b[39m     \u001b[38;5;66;03m#  results if our categories are integers that dont match our codes\u001b[39;00m\n\u001b[32m   4225\u001b[39m     \u001b[38;5;66;03m# IntervalIndex: IntervalTree has no get_loc\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/psy126/lib/python3.13/site-packages/pandas/core/frame.py:4643\u001b[39m, in \u001b[36mDataFrame._get_item_cache\u001b[39m\u001b[34m(self, item)\u001b[39m\n\u001b[32m   4638\u001b[39m res = cache.get(item)\n\u001b[32m   4639\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   4640\u001b[39m     \u001b[38;5;66;03m# All places that call _get_item_cache have unique columns,\u001b[39;00m\n\u001b[32m   4641\u001b[39m     \u001b[38;5;66;03m#  pending resolution of GH#33047\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4643\u001b[39m     loc = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4644\u001b[39m     res = \u001b[38;5;28mself\u001b[39m._ixs(loc, axis=\u001b[32m1\u001b[39m)\n\u001b[32m   4646\u001b[39m     cache[item] = res\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/psy126/lib/python3.13/site-packages/pandas/core/indexes/base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'Value'"
     ]
    }
   ],
   "source": [
    "# Compare metric vs tau-congeneric models\n",
    "from scipy.stats import chi2\n",
    "\n",
    "# Assuming stats_mete and stats_tc (for tau-congeneric) exist\n",
    "chisq_mete = stats_mete.loc['Chi-Squared', 'Value']\n",
    "df_mete = int(stats_mete.loc['DoF', 'Value'])\n",
    "chisq_tc = stats_tc.loc['Chi-Squared', 'Value']\n",
    "df_tc = int(stats_tc.loc['DoF', 'Value'])\n",
    "\n",
    "chi_diff = chisq_mete - chisq_tc\n",
    "df_diff = df_mete - df_tc\n",
    "p_value = chi2.sf(chi_diff, df_diff)\n",
    "\n",
    "print(f'Chi-square difference: {chi_diff}, DF difference: {df_diff}, p-value: {p_value}')\n",
    "print(f'AIC metric: {stats_mete.loc[\"AIC\",\"Value\"]}, AIC tau-congeneric: {stats_tc.loc[\"AIC\",\"Value\"]}')\n",
    "print(f'BIC metric: {stats_mete.loc[\"BIC\",\"Value\"]}, BIC tau-congeneric: {stats_tc.loc[\"BIC\",\"Value\"]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2005ffca",
   "metadata": {},
   "source": [
    "According to the BIC and AIC the more restricted **Essentially tau-equivalent** model has a better model fit compared to the **Tau Congeneric** measurement model (as lower values for AIC and BIC indicate better model fit). The $\\chi^2$ Test however suggests that there are no significant differences in model fit as indicated by p > .05. This result is not too surprising as we already saw quite similar loading estimates across items in the **Tau Congeneric** measurement model (see above). Therefore, restricting the loadings to equivalence isn't too much of a deviation from the **Tau Congeneric** measurement model (which does not restrict the loadings), resulting in a insignificant difference in model fit.\n",
    "\n",
    "## Tau-Equivalent Model\n",
    "\n",
    "The **Tau-equivalent** measurement model has one more restriction compared to the **Essentially tau-equivalent** model. It assumes that\n",
    "\n",
    "* items **are equivalent in their difficulty**\n",
    "* items **are equivalent in their discrimination power**\n",
    "* items are differently reliable  \n",
    "\n",
    "We therefore only get an estimate for the errors (`Variances` section). Note that we also get a `Latent Variables` section and\n",
    "a `Intecepts` section again, however, you can see that all the loadings and intercepts are fixed.\n",
    "\n",
    "## Fit the model and a quick rpy2 hint\n",
    "\n",
    "Using `rpy2` to Define Multi-Line Lavaan Models in R  \n",
    "\n",
    "When working with `rpy2` in Python to execute R commands, multi-line strings must be formatted correctly. R's **lavaan** package requires structured model definitions, but Python's `rpy2` only accepts single-line strings. To maintain readability and correctness, **`\\n`** is used to preserve line breaks.\n",
    "\n",
    "### **Example: Defining a Latent Variable Model in R**  \n",
    "\n",
    "```python\n",
    "ro.r(\"mte <<- 'eta =~ item_1 + 1*item_2 + 1*item_3 + 1*item_4 + 1*item_5 + 1*item_6\\n\"\n",
    "      \"item_1 ~ a*1\\n\"\n",
    "      \"item_2 ~ a*1\\n\"\n",
    "      \"item_3 ~ a*1\\n\"\n",
    "      \"item_4 ~ a*1\\n\"\n",
    "      \"item_5 ~ a*1\\n\"\n",
    "      \"item_6 ~ a*1'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d293e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tau-Equivalent Model using semopy\n",
    "model_mte = '''\n",
    "eta =~ lam1*item_1 + 1*item_2 + 1*item_3 + 1*item_4 + 1*item_5 + 1*item_6\n",
    "item_1 ~ a*1\n",
    "item_2 ~ a*1\n",
    "item_3 ~ a*1\n",
    "item_4 ~ a*1\n",
    "item_5 ~ a*1\n",
    "item_6 ~ a*1\n",
    "'''\n",
    "mte_model = Model(model_mte)\n",
    "mte_model.fit(dat2)\n",
    "stats_mte = calc_stats(mte_model)\n",
    "print(stats_mte)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358d9a6e",
   "metadata": {},
   "source": [
    "Again, the output looks very similar to the previous ones. The interpretation also is equivalent to before. The only difference is that the loadings (`Latent Variables` section) and the intercept (`Intercepts` section) are fixed, meaning that we assume that all items have the same discriminatory power and the same difficulty. Graphically speaking, this means that the slopes and the intercepts of the items are equivalent. The interpretation of the fit indices is analogous to the **Tau Congeneric** measurement model (see above).\n",
    "\n",
    "### Compare model fit\n",
    "\n",
    "As before, we can use the `anova()` function to compare the model fits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7526bde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare metric vs tau-equivalent models\n",
    "from scipy.stats import chi2\n",
    "\n",
    "# Using stats_mete and stats_mte from previous fits\n",
    "chisq_mete = stats_mete.loc['Chi-Squared', 'Value']\n",
    "df_mete = int(stats_mete.loc['DoF', 'Value'])\n",
    "chisq_tau_eq = stats_mte.loc['Chi-Squared', 'Value']\n",
    "df_tau_eq = int(stats_mte.loc['DoF', 'Value'])\n",
    "\n",
    "chi_diff2 = chisq_mete - chisq_tau_eq\n",
    "df_diff2 = df_mete - df_tau_eq\n",
    "p_value2 = chi2.sf(chi_diff2, df_diff2)\n",
    "\n",
    "print(f'Chi-square difference: {chi_diff2}, DF difference: {df_diff2}, p-value: {p_value2}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bcee24",
   "metadata": {},
   "source": [
    "In this comparison, the more restricted Tau-equivalent model has significantly worse fit compared to the Essentially tau-equivalent model as indicated by the significant differences in $\\chi^2$. Also AIC and BIC favor the more flexible model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "psy126",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
